# â˜ï¸ Cloud Cost Optimization Dashboard

## ğŸ“Œ Overview
This project analyzes and visualizes **AWS cloud cost and usage data** to identify cost-saving opportunities.  
It demonstrates a complete **data pipeline** â€” from raw data in AWS S3 to actionable insights in Power BI â€”  
integrating **Python, Snowflake, SQL, and visualization** to deliver automated, reliable financial analytics.

---

## ğŸ¯ Objectives
- Centralize scattered AWS billing data into a structured Snowflake warehouse.  
- Clean, transform, and validate datasets using Python.  
- Build a Power BI dashboard for cost trend analysis and service-level optimization.  
- Automate monthly updates and ensure data consistency for financial reporting.

---

## ğŸ”„ Data Pipeline

AWS S3 (Raw CUR Data)
â†“
Python (pandas for cleaning & ETL)
â†“
Snowflake (Data Modeling & Storage)
â†“
Power BI (Visualization & Reporting)


---

## âš™ï¸ Tools & Technologies
| Category | Tools Used |
|-----------|-------------|
| **Data Source** | AWS S3 (Cost & Usage Reports - CUR) |
| **ETL / Transformation** | Python, Pandas, NumPy |
| **Data Warehouse** | Snowflake (staging, warehouse, and marts schema) |
| **Visualization** | Power BI |
| **Version Control** | Git & GitHub |
| **Languages** | SQL, Python |

---
ğŸš€ Key Results

Improved dashboard refresh speed by 4Ã— using Snowflake instead of direct S3 connections.

Identified 15â€“20% potential cost reduction by visualizing unused EC2 & EBS resources.

Automated monthly updates using Python scripts and Power BI scheduled refresh.

ğŸ§© Key Learnings

Importance of separating storage (AWS S3) from analytics (Snowflake).

How to use Python for reproducible ETL workflows.

Experience building reliable pipelines that handle both scale and transparency.

ğŸ”— Future Enhancements

Integrate dbt for transformation automation.

Add Airflow for scheduling ETL tasks.

Extend dashboard to include cost forecasting using time series models in Python.

